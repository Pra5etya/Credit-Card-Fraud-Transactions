{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library / Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# graph\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# complex math\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data preparation\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "# data modeling\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "# data scoring\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# data tuning   \n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_validate\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "# pickle and .env\n",
    "from dotenv import dotenv_values\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab_round(x, pos): \n",
    "    if abs(x) >= 1e9: \n",
    "        return f'{x/1e9} B'\n",
    "    \n",
    "    elif abs(x) >= 1e6:\n",
    "        return f'{x/1e6} M'\n",
    "    \n",
    "    elif abs(x) >= 1e3:\n",
    "        return f'{x/1e3} K'\n",
    "    \n",
    "    else:\n",
    "        return f'{x}'\n",
    "    \n",
    "def val_round(x):\n",
    "    if abs(x) >= 1e9:\n",
    "        return f'{x/1e9:.2f} B'\n",
    "    \n",
    "    elif abs(x) >= 1e6:\n",
    "        return f'{x/1e6:.2f} M'\n",
    "    \n",
    "    elif abs(x) >= 1e3:\n",
    "        return f'{x/1e3:.2f} K'\n",
    "    \n",
    "    else:\n",
    "        return f'{x:.2f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk konversi tipe data\n",
    "def convert_object_columns_to_numeric(df):\n",
    "    for col in df.select_dtypes(include = ['object']).columns:  \n",
    "        try:\n",
    "            # Cek apakah semua nilai bisa dikonversi ke float\n",
    "            df[col] = pd.to_numeric(df[col], errors='raise')\n",
    "            \n",
    "            # Jika bisa, ubah ke int jika semua nilai adalah bilangan bulat\n",
    "            if all(df[col] % 1 == 0):  # Cek apakah semua nilai adalah bilangan bulat\n",
    "                df[col] = df[col].astype(int)\n",
    "\n",
    "        except ValueError:\n",
    "            pass  # Jika ada nilai non-angka, biarkan tetap object\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283712 entries, 0 to 283711\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   credit_card                283712 non-null  int64         \n",
      " 1   datetime                   283712 non-null  datetime64[ns]\n",
      " 2   long                       283712 non-null  float64       \n",
      " 3   lat                        283712 non-null  float64       \n",
      " 4   zipcode                    283712 non-null  int64         \n",
      " 5   state                      283712 non-null  object        \n",
      " 6   city                       283712 non-null  object        \n",
      " 7   year                       283712 non-null  int32         \n",
      " 8   quarter                    283712 non-null  object        \n",
      " 9   month                      283712 non-null  object        \n",
      " 10  season                     283712 non-null  object        \n",
      " 11  week_cat                   283712 non-null  object        \n",
      " 12  day                        283712 non-null  object        \n",
      " 13  credit_card_limit          283712 non-null  int64         \n",
      " 14  limit_cat                  283712 non-null  object        \n",
      " 15  transaction_dollar_amount  283712 non-null  float64       \n",
      " 16  transaction_count          283712 non-null  float64       \n",
      " 17  time_diff_per_seconds      283712 non-null  float64       \n",
      " 18  prev_long                  283712 non-null  float64       \n",
      " 19  prev_lat                   283712 non-null  float64       \n",
      " 20  distance                   283712 non-null  float64       \n",
      " 21  geo_cat                    283712 non-null  object        \n",
      " 22  fraud_status               283712 non-null  object        \n",
      " 23  cc_id                      283712 non-null  object        \n",
      " 24  trx_id                     283712 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(8), int32(1), int64(3), object(12)\n",
      "memory usage: 53.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# parameter\n",
    "share = {**dotenv_values('../.env.shared')} \n",
    "\n",
    "# read pickle\n",
    "with open(share['CLEAN_DATA'], 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "cc_df = pd.DataFrame(loaded_data)\n",
    "cc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card</th>\n",
       "      <th>datetime</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>week_cat</th>\n",
       "      <th>day</th>\n",
       "      <th>credit_card_limit</th>\n",
       "      <th>limit_cat</th>\n",
       "      <th>transaction_dollar_amount</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>time_diff_per_seconds</th>\n",
       "      <th>prev_long</th>\n",
       "      <th>prev_lat</th>\n",
       "      <th>distance</th>\n",
       "      <th>geo_cat</th>\n",
       "      <th>fraud_status</th>\n",
       "      <th>cc_id</th>\n",
       "      <th>trx_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9484591448272784</td>\n",
       "      <td>2015-07-31 09:39:48</td>\n",
       "      <td>-90.045639</td>\n",
       "      <td>29.889039</td>\n",
       "      <td>70112</td>\n",
       "      <td>la</td>\n",
       "      <td>new orleans</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015Q3</td>\n",
       "      <td>july</td>\n",
       "      <td>summer</td>\n",
       "      <td>weekday</td>\n",
       "      <td>friday</td>\n",
       "      <td>4000</td>\n",
       "      <td>very_low</td>\n",
       "      <td>17.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7642455.0</td>\n",
       "      <td>-90.151504</td>\n",
       "      <td>29.945202</td>\n",
       "      <td>11.969568</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "      <td>ac1e34e60d6ad33e82c597a0f269fe2b5e83428562d3aa...</td>\n",
       "      <td>0bc4a969dccbe3b475e9e374e53e9e3fce6dbf1e7da2fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7053196367895112</td>\n",
       "      <td>2015-07-31 11:03:48</td>\n",
       "      <td>-74.027561</td>\n",
       "      <td>40.689615</td>\n",
       "      <td>10001</td>\n",
       "      <td>ny</td>\n",
       "      <td>new york</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015Q3</td>\n",
       "      <td>july</td>\n",
       "      <td>summer</td>\n",
       "      <td>weekday</td>\n",
       "      <td>friday</td>\n",
       "      <td>18000</td>\n",
       "      <td>low</td>\n",
       "      <td>12.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2527299.0</td>\n",
       "      <td>-73.927029</td>\n",
       "      <td>40.806511</td>\n",
       "      <td>15.511210</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "      <td>1c266eb56e8271b57de874865469dc04abb5110ef52821...</td>\n",
       "      <td>03ba63876abb11634b3f875ddad559ee63940573628739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9528285469413252</td>\n",
       "      <td>2015-07-31 11:10:14</td>\n",
       "      <td>-72.139485</td>\n",
       "      <td>43.108100</td>\n",
       "      <td>3280</td>\n",
       "      <td>nh</td>\n",
       "      <td>washington</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015Q3</td>\n",
       "      <td>july</td>\n",
       "      <td>summer</td>\n",
       "      <td>weekday</td>\n",
       "      <td>friday</td>\n",
       "      <td>40000</td>\n",
       "      <td>very_high</td>\n",
       "      <td>78.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6508550.0</td>\n",
       "      <td>-72.064113</td>\n",
       "      <td>43.172281</td>\n",
       "      <td>9.404226</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "      <td>6733096fda61cddbcb8e2cd74676332d87594d058be167...</td>\n",
       "      <td>b86ab6aa560ba291acec2dd27b90f810165ff9023aab47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1845720274833905</td>\n",
       "      <td>2015-07-31 11:28:55</td>\n",
       "      <td>-89.002148</td>\n",
       "      <td>40.804323</td>\n",
       "      <td>61738</td>\n",
       "      <td>il</td>\n",
       "      <td>el paso</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015Q3</td>\n",
       "      <td>july</td>\n",
       "      <td>summer</td>\n",
       "      <td>weekday</td>\n",
       "      <td>friday</td>\n",
       "      <td>20000</td>\n",
       "      <td>medium</td>\n",
       "      <td>74.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2534699.0</td>\n",
       "      <td>-88.974492</td>\n",
       "      <td>40.720877</td>\n",
       "      <td>9.556419</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "      <td>c046d480aab2d35f98751ac74f030eff8d3c74005ac01c...</td>\n",
       "      <td>7e58fe9a9c6d89388acbd39be811095b6f13614fb16b93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7850942767136368</td>\n",
       "      <td>2015-07-31 11:38:51</td>\n",
       "      <td>-72.025675</td>\n",
       "      <td>43.210753</td>\n",
       "      <td>3280</td>\n",
       "      <td>nh</td>\n",
       "      <td>washington</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015Q3</td>\n",
       "      <td>july</td>\n",
       "      <td>summer</td>\n",
       "      <td>weekday</td>\n",
       "      <td>friday</td>\n",
       "      <td>4000</td>\n",
       "      <td>very_low</td>\n",
       "      <td>54.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1785659.0</td>\n",
       "      <td>-72.125392</td>\n",
       "      <td>43.219223</td>\n",
       "      <td>8.157130</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "      <td>c59721adc2284ba7805c637ce4b1d25046d366d12833c0...</td>\n",
       "      <td>595746461886416a18a9ab75bde2742d402301a27b8f28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        credit_card            datetime       long        lat  zipcode state  \\\n",
       "0  9484591448272784 2015-07-31 09:39:48 -90.045639  29.889039    70112    la   \n",
       "1  7053196367895112 2015-07-31 11:03:48 -74.027561  40.689615    10001    ny   \n",
       "2  9528285469413252 2015-07-31 11:10:14 -72.139485  43.108100     3280    nh   \n",
       "3  1845720274833905 2015-07-31 11:28:55 -89.002148  40.804323    61738    il   \n",
       "4  7850942767136368 2015-07-31 11:38:51 -72.025675  43.210753     3280    nh   \n",
       "\n",
       "          city  year quarter month  season week_cat     day  \\\n",
       "0  new orleans  2015  2015Q3  july  summer  weekday  friday   \n",
       "1     new york  2015  2015Q3  july  summer  weekday  friday   \n",
       "2   washington  2015  2015Q3  july  summer  weekday  friday   \n",
       "3      el paso  2015  2015Q3  july  summer  weekday  friday   \n",
       "4   washington  2015  2015Q3  july  summer  weekday  friday   \n",
       "\n",
       "   credit_card_limit  limit_cat  transaction_dollar_amount  transaction_count  \\\n",
       "0               4000   very_low                      17.99                1.0   \n",
       "1              18000        low                      12.09                1.0   \n",
       "2              40000  very_high                      78.21                1.0   \n",
       "3              20000     medium                      74.41                1.0   \n",
       "4               4000   very_low                      54.89                1.0   \n",
       "\n",
       "   time_diff_per_seconds  prev_long   prev_lat   distance geo_cat  \\\n",
       "0             -7642455.0 -90.151504  29.945202  11.969568  normal   \n",
       "1             -2527299.0 -73.927029  40.806511  15.511210  normal   \n",
       "2             -6508550.0 -72.064113  43.172281   9.404226  normal   \n",
       "3             -2534699.0 -88.974492  40.720877   9.556419  normal   \n",
       "4             -1785659.0 -72.125392  43.219223   8.157130  normal   \n",
       "\n",
       "  fraud_status                                              cc_id  \\\n",
       "0    not_fraud  ac1e34e60d6ad33e82c597a0f269fe2b5e83428562d3aa...   \n",
       "1    not_fraud  1c266eb56e8271b57de874865469dc04abb5110ef52821...   \n",
       "2    not_fraud  6733096fda61cddbcb8e2cd74676332d87594d058be167...   \n",
       "3    not_fraud  c046d480aab2d35f98751ac74f030eff8d3c74005ac01c...   \n",
       "4    not_fraud  c59721adc2284ba7805c637ce4b1d25046d366d12833c0...   \n",
       "\n",
       "                                              trx_id  \n",
       "0  0bc4a969dccbe3b475e9e374e53e9e3fce6dbf1e7da2fe...  \n",
       "1  03ba63876abb11634b3f875ddad559ee63940573628739...  \n",
       "2  b86ab6aa560ba291acec2dd27b90f810165ff9023aab47...  \n",
       "3  7e58fe9a9c6d89388acbd39be811095b6f13614fb16b93...  \n",
       "4  595746461886416a18a9ab75bde2742d402301a27b8f28...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise and Irrelevant Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Threshold Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric columns: Index(['credit_card', 'long', 'lat', 'zipcode', 'year', 'credit_card_limit',\n",
      "       'transaction_dollar_amount', 'transaction_count',\n",
      "       'time_diff_per_seconds', 'prev_long', 'prev_lat', 'distance'],\n",
      "      dtype='object')\n",
      "\n",
      "Fitur yang dipertahankan: Index(['credit_card', 'long', 'lat', 'zipcode', 'credit_card_limit',\n",
      "       'transaction_dollar_amount', 'time_diff_per_seconds', 'prev_long',\n",
      "       'prev_lat', 'distance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Drop kolom non-numerik\n",
    "df_numeric = cc_df.select_dtypes(include = ['number'])\n",
    "print(f'numeric columns: {df_numeric.columns}\\n')\n",
    "\n",
    "# Inisialisasi VarianceThreshold (misalnya, ambang batas 0.01)\n",
    "selector = VarianceThreshold(threshold = 0.01)\n",
    "df_var_selected = selector.fit_transform(df_numeric)\n",
    "\n",
    "# Fitur yang dipertahankan\n",
    "selected_features = df_numeric.columns[selector.get_support()]\n",
    "print(\"Fitur yang dipertahankan:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric column untuk modeling: Index(['transaction_dollar_amount', 'time_diff_per_seconds', 'distance'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Seleceted numeric columns\n",
    "filter_numeric = ['credit_card', 'long', 'lat', 'zipcode', 'credit_card_limit', 'prev_long', 'prev_lat']\n",
    "selected_numeric = selected_features.drop(filter_numeric)\n",
    "\n",
    "#\n",
    "print(\"Numeric column untuk modeling:\", selected_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Relevant Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE \t: ['la' 'ny' 'nh' 'il' 'pa' 'nj' 'mo' 'md' 'ca' 'tx' 'me' 'vt' 'al' 'wv'\n",
      " 'pr' 'wa' 'nc' 'ga' 'ma' 'ok' 'mi' 'ut' 'fl' 'hi' 'ia' 'nm' 'oh' 'az'\n",
      " 'va' 'in' 'ri' 'id' 'co' 'ct' 'ks'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "CITY \t: ['new orleans' 'new york' 'washington' 'el paso' 'dallas' 'houston'\n",
      " 'birmingham' 'kansas city' 'austin' 'pasadena' 'los angeles' 'fort worth'\n",
      " 'jackson' 'pittsburgh' 'portland' 'albany' 'charlotte' 'huntsville'\n",
      " 'madison' 'orlando' 'san antonio' 'seattle' 'minneapolis' 'sacramento'\n",
      " 'san francisco' 'memphis' 'dayton' 'denver' 'milwaukee' 'omaha' 'trenton'\n",
      " 'springfield' 'oklahoma city' 'charleston' 'miami' 'long beach' 'quitman'\n",
      " 'saint louis' 'friendship' 'chicago' 'salt lake city' 'richmond'\n",
      " 'pensacola' 'san diego' 'atlanta' 'honolulu' 'greensboro' 'newark'\n",
      " 'rochester' 'lafayette' 'columbus' 'staten island' 'des moines'\n",
      " 'las vegas' 'chester' 'cincinnati' 'hillsboro' 'tucson' 'buffalo'\n",
      " 'arlington' 'shreveport' 'philadelphia' 'tulsa' 'cleveland' 'saint paul'\n",
      " 'young america' 'clinton' 'amarillo' 'greenville' 'mobile' 'boise'\n",
      " 'monticello' 'indianapolis' 'cascade' 'williamsburg' 'raleigh' 'akron'\n",
      " 'huntington' 'troy' 'lake city' 'colorado springs' 'phoenix' 'fresno'\n",
      " 'auburn' 'garfield' 'evansville' 'topeka' 'cedar rapids' 'louisville'\n",
      " 'knoxville' 'oakland' 'spokane' 'manchester' 'fort wayne' 'dover' 'tampa'\n",
      " 'garden grove' 'lexington' 'alexandria' 'tacoma' 'jamaica' 'scranton'\n",
      " 'hartford' 'columbia' 'gretna' 'san jose' 'aurora' 'jacksonville'\n",
      " 'somerset' 'new haven' 'newport' 'wilmington' 'boston' 'vallejo'\n",
      " 'fort lauderdale' 'bronx' 'wichita' 'lancaster' 'detroit' 'baltimore'\n",
      " 'bristol' 'corpus christi' 'roanoke'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "QUARTER \t: ['2015Q3' '2015Q4'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "MONTH \t: ['july' 'august' 'september' 'october'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "SEASON \t: ['summer' 'fall'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "WEEK_CAT \t: ['weekday' 'weekend'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "DAY \t: ['friday' 'saturday' 'sunday' 'monday' 'tuesday' 'wednesday' 'thursday'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "LIMIT_CAT \t: ['very_low' 'low' 'very_high' 'medium' 'high'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "GEO_CAT \t: ['normal' 'anomaly'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "FRAUD_STATUS \t: ['not_fraud' 'fraud'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "CC_ID \t: ['ac1e34e60d6ad33e82c597a0f269fe2b5e83428562d3aabd566ee7bbd443f5d9'\n",
      " '1c266eb56e8271b57de874865469dc04abb5110ef52821756fc7cb5d40ba9b5e'\n",
      " '6733096fda61cddbcb8e2cd74676332d87594d058be16773a54427d6bb6f80ca' ...\n",
      " 'f75a5c688ac926a97d47828ad7c2309b8dd2dcb2879c6550e34c59db1cb673fa'\n",
      " 'e5a25692318622e2a82cb61b42af51abe2244e73dc0e33daf4a1650052eca98d'\n",
      " '09759c6a2afb74247dbbf11e78973f678f9351264e87125f96d9e2d8c843a4b9'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n",
      "TRX_ID \t: ['0bc4a969dccbe3b475e9e374e53e9e3fce6dbf1e7da2fe45ca3f73ce7c84d716'\n",
      " '03ba63876abb11634b3f875ddad559ee63940573628739c3bf69e9690b5c9424'\n",
      " 'b86ab6aa560ba291acec2dd27b90f810165ff9023aab47ed84738319b19867c3' ...\n",
      " '8dc5ef52831371bafcdedc8beffe6af52736dbf7077224e14ccd912df2b56ffc'\n",
      " '41004c638bb1e1e3584902c8f22fa58953dc5b1a47ec084e54f21ce0fbe617f7'\n",
      " '1582114f0966f642cc74253d4750fce5b74f1789533724588e20055aeb787f9c'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Column Category\n",
    "check_cat = cc_df.select_dtypes(include = ['object'])\n",
    "\n",
    "for i in check_cat.columns:\n",
    "    print(f'{i.upper()} \\t: {check_cat[i].unique()} \\n')\n",
    "    print(f'{\"-\" * 50} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objetc columns: Index(['state', 'city', 'quarter', 'month', 'season', 'week_cat', 'day',\n",
      "       'limit_cat', 'geo_cat', 'fraud_status', 'cc_id', 'trx_id'],\n",
      "      dtype='object')\n",
      "\n",
      "Object column untuk modeling: Index(['limit_cat', 'geo_cat', 'fraud_status'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop kolom numerik\n",
    "df_obj = cc_df.select_dtypes(include = ['object'])\n",
    "print(f'objetc columns: {df_obj.columns}\\n')\n",
    "\n",
    "# selected object columns\n",
    "filter_obj = ['limit_cat', 'geo_cat', 'fraud_status']\n",
    "selected_object = df_obj[filter_obj].columns\n",
    "\n",
    "#\n",
    "print(\"Object column untuk modeling:\", selected_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_dollar_amount</th>\n",
       "      <th>time_diff_per_seconds</th>\n",
       "      <th>distance</th>\n",
       "      <th>limit_cat</th>\n",
       "      <th>geo_cat</th>\n",
       "      <th>fraud_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>-7642455.0</td>\n",
       "      <td>11.969568</td>\n",
       "      <td>very_low</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.09</td>\n",
       "      <td>-2527299.0</td>\n",
       "      <td>15.511210</td>\n",
       "      <td>low</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.21</td>\n",
       "      <td>-6508550.0</td>\n",
       "      <td>9.404226</td>\n",
       "      <td>very_high</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.41</td>\n",
       "      <td>-2534699.0</td>\n",
       "      <td>9.556419</td>\n",
       "      <td>medium</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.89</td>\n",
       "      <td>-1785659.0</td>\n",
       "      <td>8.157130</td>\n",
       "      <td>very_low</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_dollar_amount  time_diff_per_seconds   distance  limit_cat  \\\n",
       "0                      17.99             -7642455.0  11.969568   very_low   \n",
       "1                      12.09             -2527299.0  15.511210        low   \n",
       "2                      78.21             -6508550.0   9.404226  very_high   \n",
       "3                      74.41             -2534699.0   9.556419     medium   \n",
       "4                      54.89             -1785659.0   8.157130   very_low   \n",
       "\n",
       "  geo_cat fraud_status  \n",
       "0  normal    not_fraud  \n",
       "1  normal    not_fraud  \n",
       "2  normal    not_fraud  \n",
       "3  normal    not_fraud  \n",
       "4  normal    not_fraud  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "model_col = selected_numeric.append(selected_object)\n",
    "\n",
    "# \n",
    "model_df = cc_df[model_col]\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Encoding Columns: ['limit_cat']\n",
      "One-Hot Encoding Columns: ['geo_cat', 'fraud_status']\n",
      "Numeric Columns: ['transaction_dollar_amount', 'time_diff_per_seconds', 'distance']\n"
     ]
    }
   ],
   "source": [
    "# Daftar kolom untuk label encoding (kolom ordinal)\n",
    "encoding_set = {'limit_cat'}\n",
    "\n",
    "# Inisialisasi list untuk menyimpan kolom yang telah dikelompokkan\n",
    "ordinal_cols = []\n",
    "one_hot_cols = []\n",
    "numeric_cols = []\n",
    "\n",
    "# Mengelompokkan kolom berdasarkan tipe data\n",
    "for col in model_df.columns:\n",
    "    if cc_df[col].dtype in ['int', 'float']:\n",
    "        numeric_cols.append(col)\n",
    "\n",
    "    elif cc_df[col].dtype == 'object':\n",
    "        if col in encoding_set:\n",
    "            ordinal_cols.append(col)\n",
    "\n",
    "        else:\n",
    "            one_hot_cols.append(col)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(\"Ordinal Encoding Columns:\", ordinal_cols)\n",
    "print(\"One-Hot Encoding Columns:\", one_hot_cols)\n",
    "print(\"Numeric Columns:\", numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMIT_CAT \t: ['very_low' 'low' 'very_high' 'medium' 'high'] \n",
      "\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Ordinal Columns\n",
    "for i in ordinal_cols:\n",
    "    print(f'{i.upper()} \\t: {check_cat[i].unique()} \\n')\n",
    "    print(f'{\"-\" * 50} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan urutan kategori masing-masing kolom\n",
    "oridnal_cat = [\n",
    "    [\"very_low\", \"low\", \"medium\", \"high\", \"very_high\"],   # Urutan untuk limit_cat\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformasi\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore', sparse_output = True, max_categories = 50)), \n",
    "    # ('svd', TruncatedSVD(n_components = 100))  # Mengurangi dimensi fitur kategori\n",
    "])\n",
    "ordinal_transformer = OrdinalEncoder(categories = oridnal_cat, handle_unknown = 'use_encoded_value', unknown_value = -1)\n",
    "\n",
    "# Column Transformer\n",
    "prep_stage_2 = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"num\", numerical_transformer, numeric_cols), \n",
    "        (\"cat\", categorical_transformer, one_hot_cols), \n",
    "        (\"ord\", ordinal_transformer, ordinal_cols)\n",
    "    ], remainder = \"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data menggunakan fit_transform\n",
    "model_df = prep_stage_2.fit_transform(model_df)\n",
    "\n",
    "# Get name column from fit_transform\n",
    "model_df = pd.DataFrame(model_df, columns = prep_stage_2.get_feature_names_out())\n",
    "\n",
    "# Hilangkan prefix (misalnya, \"num__\", \"cat__\", \"out__\")\n",
    "clean_columns = [col.split(\"__\", 1)[-1] for col in model_df.columns]\n",
    "model_df.columns = clean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total null columns: Series([], dtype: int64) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan total null pada setiap kolom\n",
    "null_columns = model_df.isnull().sum()[model_df.isnull().sum() > 0]\n",
    "print(f'Total null columns: {null_columns} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283712 entries, 0 to 283711\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   transaction_dollar_amount  283712 non-null  float64\n",
      " 1   time_diff_per_seconds      283712 non-null  float64\n",
      " 2   distance                   283712 non-null  float64\n",
      " 3   geo_cat_anomaly            283712 non-null  float64\n",
      " 4   geo_cat_normal             283712 non-null  float64\n",
      " 5   fraud_status_fraud         283712 non-null  float64\n",
      " 6   fraud_status_not_fraud     283712 non-null  float64\n",
      " 7   limit_cat                  283712 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 17.3 MB\n"
     ]
    }
   ],
   "source": [
    "# check data type after transform\n",
    "model_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 283712 entries, 0 to 283711\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   transaction_dollar_amount  283712 non-null  float64\n",
      " 1   time_diff_per_seconds      283712 non-null  float64\n",
      " 2   distance                   283712 non-null  float64\n",
      " 3   geo_cat_anomaly            283712 non-null  float64\n",
      " 4   geo_cat_normal             283712 non-null  float64\n",
      " 5   fraud_status_fraud         283712 non-null  float64\n",
      " 6   fraud_status_not_fraud     283712 non-null  float64\n",
      " 7   limit_cat                  283712 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 17.3 MB\n"
     ]
    }
   ],
   "source": [
    "# change object after transform\n",
    "model_df = convert_object_columns_to_numeric(model_df)\n",
    "model_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_dollar_amount</th>\n",
       "      <th>time_diff_per_seconds</th>\n",
       "      <th>distance</th>\n",
       "      <th>geo_cat_anomaly</th>\n",
       "      <th>geo_cat_normal</th>\n",
       "      <th>fraud_status_fraud</th>\n",
       "      <th>fraud_status_not_fraud</th>\n",
       "      <th>limit_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.980072</td>\n",
       "      <td>-2.394849</td>\n",
       "      <td>-0.169832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.088841</td>\n",
       "      <td>-0.792138</td>\n",
       "      <td>-0.167818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130110</td>\n",
       "      <td>-2.039567</td>\n",
       "      <td>-0.171291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060055</td>\n",
       "      <td>-0.794456</td>\n",
       "      <td>-0.171205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.299804</td>\n",
       "      <td>-0.559763</td>\n",
       "      <td>-0.172001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_dollar_amount  time_diff_per_seconds  distance  \\\n",
       "0                  -0.980072              -2.394849 -0.169832   \n",
       "1                  -1.088841              -0.792138 -0.167818   \n",
       "2                   0.130110              -2.039567 -0.171291   \n",
       "3                   0.060055              -0.794456 -0.171205   \n",
       "4                  -0.299804              -0.559763 -0.172001   \n",
       "\n",
       "   geo_cat_anomaly  geo_cat_normal  fraud_status_fraud  \\\n",
       "0              0.0             1.0                 0.0   \n",
       "1              0.0             1.0                 0.0   \n",
       "2              0.0             1.0                 0.0   \n",
       "3              0.0             1.0                 0.0   \n",
       "4              0.0             1.0                 0.0   \n",
       "\n",
       "   fraud_status_not_fraud  limit_cat  \n",
       "0                     1.0        0.0  \n",
       "1                     1.0        1.0  \n",
       "2                     1.0        4.0  \n",
       "3                     1.0        2.0  \n",
       "4                     1.0        0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df.drop(columns = [\"fraud_status_not_fraud\", \"geo_cat_normal\", \"limit_cat\"])  # Buang kolom asli kategori\n",
    "y = model_df[\"fraud_status_fraud\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.37111115, 4.43282318, 4.21673894, 4.29628944, 4.34572577]),\n",
       " 'score_time': array([0.13819432, 0.14283514, 0.15345907, 0.13316941, 0.14941764]),\n",
       " 'test_accuracy': array([1., 1., 1., 1., 1.]),\n",
       " 'test_precision': array([1., 1., 1., 1., 1.]),\n",
       " 'test_recall': array([1., 1., 1., 1., 1.]),\n",
       " 'test_f1': array([1., 1., 1., 1., 1.]),\n",
       " 'test_roc_auc': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define pipeline\n",
    "base_model_pipe = Pipeline([\n",
    "    (\"model\", RandomForestClassifier(n_estimators = 100, random_state = 42))\n",
    "])\n",
    "\n",
    "# Cross-validation scores with multiple metrics\n",
    "val_score = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "cv_results = cross_validate(base_model_pipe, X_train, y_train, cv = 5, scoring = val_score)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy: 1.0000\n",
      "Cross-validation Precision: 1.0000\n",
      "Cross-validation Recall: 1.0000\n",
      "Cross-validation F1-score: 1.0000\n",
      "Cross-validation AUC-ROC: 1.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross-validation Accuracy: {cv_results['test_accuracy'].mean():.4f}\")\n",
    "print(f\"Cross-validation Precision: {cv_results['test_precision'].mean():.4f}\")\n",
    "print(f\"Cross-validation Recall: {cv_results['test_recall'].mean():.4f}\")\n",
    "print(f\"Cross-validation F1-score: {cv_results['test_f1'].mean():.4f}\")\n",
    "print(f\"Cross-validation AUC-ROC: {cv_results['test_roc_auc'].mean():.4f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     55748\n",
      "         1.0       1.00      1.00      1.00       995\n",
      "\n",
      "    accuracy                           1.00     56743\n",
      "   macro avg       1.00      1.00      1.00     56743\n",
      "weighted avg       1.00      1.00      1.00     56743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline\n",
    "base_model_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = base_model_pipe.predict(X_test)\n",
    "\n",
    "# Evaluasi Model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "AUC-ROC Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check optimal cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation: 2 -> Mean: 1.0000, Std: 0.0000\n",
      "Cross Validation: 3 -> Mean: 1.0000, Std: 0.0000\n",
      "Cross Validation: 5 -> Mean: 1.0000, Std: 0.0000\n",
      "Cross Validation: 10 -> Mean: 1.0000, Std: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "cv_values = [2, 3, 5, 10]  # Coba berbagai nilai cv\n",
    "scores = []\n",
    "\n",
    "for cv in cv_values:\n",
    "    cv_score = cross_val_score(base_model_pipe, \n",
    "                               X_train, \n",
    "                               y_train, \n",
    "                               cv = cv, \n",
    "                               scoring = 'recall')\n",
    "    \n",
    "    mean_score = np.mean(cv_score)\n",
    "    std_score = np.std(cv_score)\n",
    "    \n",
    "    scores.append((cv, mean_score, std_score))\n",
    "    print(f\"Cross Validation: {cv} -> Mean: {mean_score:.4f}, Std: {std_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1956161212.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[27], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    sam =\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sam ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# n_iter_values = [10, 20, 50, 100]  # Uji berbagai nilai\n",
    "# scores = []\n",
    "\n",
    "# param_grid = {\n",
    "#     \"model__n_estimators\": [50, 100, 200, 500],\n",
    "#     \"model__max_depth\": [None, 10, 20, 30],\n",
    "#     \"model__min_samples_split\": [2, 5, 10, 20],\n",
    "#     \"model__min_samples_leaf\": [1, 2, 5, 10],\n",
    "#     \"model__max_features\": [\"sqrt\", \"log2\", None],\n",
    "#     \"model__bootstrap\": [True, False],\n",
    "#     \"model__class_weight\": [\"balanced\", \"balanced_subsample\", None]\n",
    "# }\n",
    "\n",
    "# for n in n_iter_values:\n",
    "#     random_search = RandomizedSearchCV(\n",
    "#         base_model_pipe, \n",
    "#         param_grid, \n",
    "#         n_iter = n, \n",
    "#         cv = 3, \n",
    "#         scoring = \"recall\", \n",
    "#         n_jobs = -1, \n",
    "#         random_state = 42\n",
    "#     )\n",
    "\n",
    "#     random_search.fit(X_train, y_train)\n",
    "#     scores.append(random_search.best_score_)\n",
    "\n",
    "# plt.plot(n_iter_values, scores, marker='o')\n",
    "# plt.xlabel(\"n_iter\")\n",
    "# plt.ylabel(\"Best CV Score\")\n",
    "# plt.title(\"Evaluasi n_iter di RandomizedSearchCV\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search = RandomizedSearchCV(\n",
    "#     base_model_pipe,    # Model pipeline\n",
    "#     param_distributions = param_grid,   # Gunakan param_grid yang sama\n",
    "#     n_iter = 20,    # Batasi jumlah kombinasi yang diuji (misal 20)\n",
    "#     cv = 5,     # Cross-validation 5-fold\n",
    "#     scoring = [\"precision\", \"recall\", \"f1\"], \n",
    "#     refit = \"recall\",\n",
    "#     n_jobs = -1,    # Gunakan semua core CPU\n",
    "#     verbose = 2,    # Tampilkan progress\n",
    "#     random_state = 42   # Pastikan hasil tetap reproducible\n",
    "# )\n",
    "\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# best_model = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pilih model terbaik\n",
    "# random_results = random_search.cv_results_\n",
    "# random_results.keys()\n",
    "\n",
    "# print(\"Best parameters based on recall:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cek metrik lainnya jika menggunakan multiple scoring\n",
    "# print(\"Best model based on precision:\", np.max(random_results['mean_test_precision']))\n",
    "# print(\"Best model based on F1-score:\", np.max(random_results['mean_test_f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluasi Model Terbaik\n",
    "# y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Metrik tambahan\n",
    "# accuracy = accuracy_score(y_test, y_pred_best)\n",
    "# precision = precision_score(y_test, y_pred_best)\n",
    "# recall = recall_score(y_test, y_pred_best)\n",
    "# f1 = f1_score(y_test, y_pred_best)\n",
    "# auc_score = roc_auc_score(y_test, y_pred_best)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1-Score: {f1:.4f}\")\n",
    "# print(f\"AUC-ROC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [50, 100, 200, 500],\n",
    "    \"model__max_depth\": [None, 10, 20, 30],\n",
    "    \"model__min_samples_split\": [2, 5, 10, 20],\n",
    "    \"model__min_samples_leaf\": [1, 2, 5, 10],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"model__bootstrap\": [True, False],\n",
    "    \"model__class_weight\": [\"balanced\", \"balanced_subsample\", None]\n",
    "}\n",
    "\n",
    "halving_search = HalvingGridSearchCV(\n",
    "    base_model_pipe,    # Model pipeline\n",
    "    param_grid,     # Gunakan param_grid yang sama\n",
    "    factor = 3,     # Kandidat dikurangi 3x di setiap iterasi\n",
    "    cv = 3,     # Cross-validation lebih kecil untuk kecepatan\n",
    "    scoring = \"recall\",    # Single Metrik \n",
    "    refit = True, \n",
    "    n_jobs = -1,    # Gunakan semua core CPU\n",
    "    verbose = 2,    # Tampilkan progress\n",
    "    random_state = 42   # Untuk hasil yang konsisten\n",
    ")\n",
    "\n",
    "halving_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = halving_search.best_estimator_\n",
    "\n",
    "# more than 1/2 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pilih model terbaik berdasarkan akurasi\n",
    "halving_results = halving_search.cv_results_\n",
    "halving_results.keys()\n",
    "\n",
    "print(\"Best parameters based on recall:\", halving_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cek metrik lainnya jika menggunakan multiple scoring\n",
    "print(\"Best model based on precision:\", np.max(halving_results['mean_test_precision']))\n",
    "print(\"Best model based on F1-score:\", np.max(halving_results['mean_test_f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi Model Terbaik\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrik tambahan\n",
    "accuracy = accuracy_score(y_test, y_pred_best)\n",
    "precision = precision_score(y_test, y_pred_best)\n",
    "recall = recall_score(y_test, y_pred_best)\n",
    "f1 = f1_score(y_test, y_pred_best)\n",
    "auc_score = roc_auc_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Fraud\", \"Fraud\"], yticklabels=[\"Non-Fraud\", \"Fraud\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Probabilitas prediksi\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Hitung ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=\"AUC = {:.2f}\".format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentukan folder tujuan\n",
    "dir_name = 'datamart'\n",
    "folder_path = f\"../{dir_name}\"\n",
    "\n",
    "# Cek apakah folder sudah ada, jika belum buat foldernya\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    \n",
    "    print(f\"Directory '{dir_name}' created successfully.\")\n",
    "\n",
    "else: \n",
    "    print(f'Directory has already been created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# parameter\n",
    "share = {**dotenv_values('../.env.shared')} \n",
    "\n",
    "# Simpan model terbaik ke file\n",
    "joblib.dump(best_model, share['FRAUD_DETECT'])\n",
    "\n",
    "print(\"Model berhasil disimpan!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model yang sudah disimpan\n",
    "\n",
    "# parameter\n",
    "share = {**dotenv_values('../.env.shared')} \n",
    "\n",
    "loaded_model = joblib.load(share['FRAUD_DETECT'])\n",
    "\n",
    "print(\"Model berhasil dimuat kembali!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi pada data baru\n",
    "y_pred_new = loaded_model.predict(X_test)\n",
    "\n",
    "# Evaluasi kembali model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_new))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh data baru (pastikan sesuai format dataset)\n",
    "new_transaction = np.array([[1000, 0, 1, 0, 500, 20]])  # Ubah sesuai dataset\n",
    "\n",
    "# Standardisasi data baru jika sebelumnya menggunakan scaler\n",
    "scaler = StandardScaler()\n",
    "new_transaction_scaled = scaler.transform(new_transaction)\n",
    "\n",
    "# Prediksi\n",
    "prediction = loaded_model.predict(new_transaction_scaled)\n",
    "\n",
    "# Hasil prediksi\n",
    "print(\"Prediksi: Fraud\" if prediction[0] == 1 else \"Prediksi: Not Fraud\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
